#!/usr/bin/python3
# Read all queues and write their contents to queues.json

import json
import logging
import os
import tempfile

from helpers.utils import amqp_connect, get_autopkgtest_cloud_conf, get_release_arches
from pika.exceptions import AMQPError

AMQP_CONTEXTS = ["", "huge-", "ppa-", "upstream-"]

logger = logging.getLogger()


class AutopkgtestQueueContents:
    def __init__(self, amqp_conn):
        assert amqp_conn is not None

        self.amqp_conn = amqp_conn
        self.channel = self.amqp_conn.channel()
        logger.info("Connected to AMQP")

    def get_queue_requests(self, queue_name):
        """Return list of pending requests in AMQP queue."""
        requests = []

        # non-acking read of all requests to inspect the queue
        while True:
            method, _, body = self.channel.basic_get(queue_name)
            if body is None:
                break
            requests.append(body)
            logging.debug(f"{queue_name}: name {body}")
            # reject the request so it becomes available to the workers
            self.channel.basic_reject(delivery_tag=method.delivery_tag, requeue=True)

        res = []
        for r in requests:
            if isinstance(r, bytes):
                r = r.decode("UTF-8")
            try:
                req = r.split("\n", 1)
                if len(req) > 1:
                    params = json.loads(req[1])
                    if params.get("readable-by", False) or params.get(
                        "swiftuser", False
                    ):
                        r = "private job"
                else:
                    logging.warning(f"Found malformed request {r}")
                    r = "malformed request"
                res.append(r)
            except (ValueError, IndexError) as e:
                logging.warning(f"Received invalid request {r}: {repr(e)}")

        return res

    def get_queue_contents(self):
        """Get queue contents from AMQP and cache them on disk."""
        release_arches = get_release_arches()
        all_arches = set()

        channel = self.amqp_conn.channel()
        channel.basic_qos(0, 1)

        result = {}
        for context in AMQP_CONTEXTS:
            for release, arches in release_arches.items():
                for arch in arches:
                    queue_name = f"debci-{context}{release}-{arch}"
                    try:
                        requests = self.get_queue_requests(queue_name)
                    except AMQPError:
                        logging.warning(f"Failed reading data from queue {queue_name}")
                        continue
                    queue_size = 0
                    if requests:
                        queue_size = len(requests)
                    logging.info(f"queue {queue_name} has {queue_size} items")
                    result.setdefault(context, {}).setdefault(release, {})[arch] = {
                        "size": queue_size,
                        "requests": requests,
                    }
                    all_arches.add(arch)

        queued = {
            "releases": list(release_arches.keys()),
            "arches": sorted(all_arches),
            "queues": result,
        }

        return queued


if __name__ == "__main__":
    amqp_conn = amqp_connect()
    cp = get_autopkgtest_cloud_conf()

    queues_file = cp["web"]["amqp_queue_cache"]

    aq = AutopkgtestQueueContents(amqp_conn)
    queue_contents = aq.get_queue_contents()

    with tempfile.NamedTemporaryFile(
        mode="w", dir=os.path.dirname(queues_file), delete=False, delete_on_close=False
    ) as tf:
        json.dump(queue_contents, tf, indent=2)
        umask = os.umask(0)
        os.umask(umask)
        os.chmod(tf.name, 0o644 & ~umask)
        os.rename(tf.name, queues_file)
