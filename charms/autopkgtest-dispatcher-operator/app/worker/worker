#!/usr/bin/python3
# autopkgtest cloud worker
# Author: Martin Pitt <martin.pitt@ubuntu.com>
#
# Requirements: python3-amqp python3-swiftclient python3-influxdb
# Requirements for running autopkgtest from git: python3-debian libdpkg-perl
#
# pylint: disable=too-many-lines,line-too-long

import argparse
import configparser
import fnmatch
import hashlib
import json
import logging
import os
import random
import re
import shutil
import signal
import socket
import subprocess
import sys
import tempfile
import time
import uuid

import amqp
import distro_info
import swiftclient
import systemd.journal
from influxdb import InfluxDBClient
from influxdb.exceptions import InfluxDBClientError

ALL_RELEASES = distro_info.UbuntuDistroInfo().get_all(result="object")

try:
    INFLUXDB_CONTEXT = os.environ["INFLUXDB_CONTEXT"]
    INFLUXDB_DATABASE = os.environ["INFLUXDB_DATABASE"]
    INFLUXDB_HOSTNAME = os.environ["INFLUXDB_HOSTNAME"]
    INFLUXDB_PASSWORD = os.environ["INFLUXDB_PASSWORD"]
    INFLUXDB_PORT = os.environ["INFLUXDB_PORT"]
    INFLUXDB_USERNAME = os.environ["INFLUXDB_USERNAME"]

    influx_client = InfluxDBClient(
        INFLUXDB_HOSTNAME,
        INFLUXDB_PORT,
        INFLUXDB_USERNAME,
        INFLUXDB_PASSWORD,
        INFLUXDB_DATABASE,
    )
except KeyError:
    influx_client = None

my_path = os.path.dirname(__file__)
root_path = os.path.dirname(os.path.abspath(my_path))
debug = False
args = None
cfg = None
swift_creds = {}
swift_upload = True
exit_requested = None
running_test = False
status_exchange_name = "teststatus.fanout"
complete_exchange_name = "testcomplete.fanout"
amqp_con = None
systemd_logging_handler = systemd.journal.JournalHandler()
hostname = socket.gethostname()

# Read in from config files
big_packages = set()
long_tests = set()
never_run = set()
esm_specials = set()

ARCH_RELEASE_ALLOW_MAPPING = {
    "trusty": ["amd64", "i386"],
    "xenial": ["amd64", "i386", "s390x"],
}

FAIL_CODES = (4, 6, 12, 14, 20)
SUCCESS_CODES = (0, 2, 8)

KEYS_FOR_ADDITIONAL_PARAMS = ["all-proposed", "testname"]

# In the case of a tmpfail, look for these strings in the log and if they're
# found, consider this a real failure instead. This is useful if the test
# breaks the testbed so much that autopkgtest can't report a failure properly -
# in this case the nova script will output the console log.

# Note that you get *three* tries, and you need to fail in this way every time
# for the failure to be converted from a tmpfail to a real one.
FAIL_STRINGS = [
    "Kernel panic - not syncing:",
    "Freezing execution.",
    "Out of memory: Kill process",
    "error: you need to load the kernel first.",
    "Faulting instruction address:",
    "Call Trace:",
]
TEMPORARY_TEST_FAIL_STRINGS = [
    "Could not connect to ftpmaster.internal:80",
    "Cannot initiate the connection to ppa.launchpad.net:80",
    "Failed to fetch http://ftpmaster.internal/",
    '" failed with stderr "error: Get https://0.0.0.0/1.0/operations/',
    "RecursionError: maximum recursion depth exceeded in comparison",  # LP: #1908506
    "Temporary failure resolving 'archive.ubuntu.com'",
    "Temporary failure resolving 'ports.ubuntu.com'",
    "Temporary failure resolving 'ftpmaster.internal'",
    "Temporary failure in name resolution",
    "Unable to connect to ftpmaster.internal:http:",
    "/tmp/autopkgtest-run-wrapper: command not found",  # LP: #1896466
    ": error cleaning up:",
    " has modification time ",  # clock skew, LP: #1880839
    "OSError: [Errno 28] No space left on device",
    "keystoneauth1.exceptions.connection.ConnectFailure",
    "novaclient.exceptions.ResourceInErrorState",  # failure with the VM
]

# If we repeatedly time out when installing, there's probably a problem with
# one of the packages' maintainer scripts.
FAIL_STRINGS_REGEX = [
    r"timed out on command.*apt-get install",
    r"Removing (?:ubuntu-minimal|netplan\.io)",
]

# Some packages can provoke specific breakage. For most packages, this would be
# a sign of infrastructure trouble, but for these we should play it safe and
# consider these to be regressions. If they *are* infrastructure problems,
# we'll have to retry them.
FAIL_PKG_STRINGS = {
    "systemd*": [
        "timed out waiting for testbed to reboot",
        "Timed out on waiting for ssh connection",
        "Temporary failure resolving",
        "VirtSubproc.Timeout",
        "ERROR: testbed failure: testbed auxverb failed with exit code 255",
        "ERROR: testbed failure: rules extract failed with exit code 100 (apt failure)",
    ],
    "linux-*": [
        "timed out waiting for testbed to reboot",
        "Timed out on waiting for ssh connection",
        "ERROR: testbed failure: testbed auxverb failed",
        "/bin/bash: No such file or directory",
    ],
    "libnfs": [
        "timed out waiting for testbed to reboot",
        "Timed out on waiting for ssh connection",
        "ERROR: testbed failure: testbed auxverb failed",
    ],
    "cluster-glue": ["timed out waiting for testbed to reboot"],
    "lxc": ["Error starting container"],
    "nplan": ["VirtSubproc.Timeout"],
    "netplan.io": [
        "VirtSubproc.Timeout",
        "Timed out on waiting for ssh connection",
        "Temporary failure resolving",
    ],
    "dnspython": ["dns.exception.Timeout"],
    "pcapfix": ["Cannot open input file: No such file or directory"],
    "makedumpfile": [
        "This does not look like a tar archive",
        "Timed out on waiting for ssh connection",
    ],
    "kdump-tools": [
        "This does not look like a tar archive",
        "Timed out on waiting for ssh connection",
    ],
    "llvm-toolchain-*": [
        "clang: error: unable to execute command: Segmentation fault (core dumped)"
    ],
}

# Exemptions from TEMPORARY_TEST_FAIL_STRINGS / FAIL_{PKG_,}STRINGS
# Adding dbconfig-common here is a hack of sorts LP: #2001714
OK_PKG_STRINGS = {
    "dbconfig-common": ["Temporary failure in name resolution"],
    "debspawn": [
        "Temporary failure resolving 'archive.ubuntu.com'",
        "Temporary failure resolving 'ports.ubuntu.com'",
        "Temporary failure resolving 'ftpmaster.internal'",
    ],
    "dnspython": ["Temporary failure in name resolution"],
    "systemd*": ["Temporary failure in name resolution"],
}


def submit_metric(architecture, code, pkgname, current_region, retry, release):
    if influx_client is None:
        return

    region = (
        current_region
        if current_region.startswith("lxd")
        else current_region.split("-")[0]
    )

    point = {
        "measurement": "autopkgtest_exit_event",
        "fields": {"exited": True},
        "tags": {
            "arch": architecture,
            "exit_status": code,
            "instance": INFLUXDB_CONTEXT,
            "package": pkgname,
            "region": region,
            "retry": retry,
            "series": release,
        },
    }
    try:
        influx_client.write_points([point])
    except InfluxDBClientError as err:
        logging.error("Write to InfluxDB failed: %s" % err)
        return


def getglob(d, glob, default=None):
    for k in d:
        if fnmatch.fnmatch(glob, k):
            return d[k]

    return default


def term_handler(signum, frame):
    """SIGTERM handler, for clean exit after current test"""

    logging.info("Caught SIGTERM, requesting exit")
    global exit_requested
    exit_requested = 0
    if not running_test:
        amqp_con.close()


def hup_handler(signum, frame):
    """SIGHUP handler, for restarting after current test"""

    logging.info("Caught SIGHUP, requesting restart")
    global exit_requested
    exit_requested = 10
    if not running_test:
        amqp_con.close()


def parse_args():
    """Parse command line and return argparse.args object"""

    parser = argparse.ArgumentParser()
    parser.add_argument(
        "-a",
        "--architecture",
        default=subprocess.check_output(
            ["dpkg", "--print-architecture"], universal_newlines=True
        ).strip(),
        help="architecture to watch queues for (default: machine arch)",
    )
    parser.add_argument(
        "-c",
        "--config",
        default=os.path.join(my_path, "worker.conf"),
        help="configuration file (default: %(default)s)",
    )
    parser.add_argument(
        "-d",
        "--debug",
        action="store_true",
        default=False,
        help="enable debug logging",
    )
    parser.add_argument(
        "-v",
        "--variable",
        metavar="KEY=VALUE",
        action="append",
        default=[],
        help="define additional variable for given config file",
    )
    return parser.parse_args()


def read_per_package_configs(cfg):
    def read_per_package_file(filename):
        out = set()
        with open(filename, "r") as f:
            entries = {
                line.strip() for line in f.readlines() if not line.startswith("#")
            }

            for entry in entries:
                package = None
                arch = None
                release = None
                try:
                    (package, arch, release) = entry.split("/", 3)
                except ValueError:
                    release = "all"
                    try:
                        (package, arch) = entry.split("/", 2)
                    except ValueError:
                        arch = "all"
                        package = entry
                finally:
                    out.add(f"{package}/{arch}/{release}")
            return out

    global big_packages, long_tests, never_run, esm_specials

    dir = cfg.get("autopkgtest", "per_package_config_dir").strip()

    big_packages = read_per_package_file(os.path.join(dir, "big_packages"))
    long_tests = read_per_package_file(os.path.join(dir, "long_tests"))
    never_run = read_per_package_file(os.path.join(dir, "never_run"))
    esm_specials = read_per_package_file(os.path.join(dir, "esm_specials"))


def request_matches_per_package(package, arch, release, s):
    return (
        any(fnmatch.fnmatchcase(f"{package}/{arch}/{release}", entry) for entry in s)
        or any(fnmatch.fnmatchcase(f"{package}/all/{release}", entry) for entry in s)
        or any(fnmatch.fnmatchcase(f"{package}/{arch}/all", entry) for entry in s)
        or any(fnmatch.fnmatchcase(f"{package}/all/all", entry) for entry in s)
    )


def inject_info_into_testinfo(
    testinfo: dict,
    additional_params: dict,
    test_uuid: str,
) -> dict:
    testinfo["uuid"] = test_uuid
    for key in KEYS_FOR_ADDITIONAL_PARAMS:
        testinfo[key] = additional_params.get(key)
    testinfo["worker-unit"] = hostname
    return testinfo


def process_output_dir(
    dir,
    pkgname,
    code,
    triggers,
    test_uuid,
    additional_params: dict,
):
    """Post-process output directory"""

    files = set(os.listdir(dir))

    # LP: #1641888
    # In failure cases where we don't know the version, write 'unknown' out as
    # the version, so that frontends (e.g. autopkgtest-web, or britney) can
    # display the result.
    if (code in FAIL_CODES or code == 16) and "testpkg-version" not in files:
        logging.warning(
            'Code %d returned and no testpkg-version - returning "unknown" for %s'
            % (code, pkgname)
        )
        with open(os.path.join(dir, "testpkg-version"), "w") as testpkg_version:
            testpkg_version.write("%s unknown" % pkgname)
        files.add("testpkg-version")
        # we might need to fake testinfo.json up too, depending on how
        # autopkgtest failed. britney uses this to associate results with
        # requests
        if "testinfo.json" not in files and triggers:
            logging.warning("...testinfo.json is missing too, faking one up")
            triggers = " ".join(triggers)
            with open(os.path.join(dir, "testinfo.json"), "w") as testinfo:
                d = {"custom_environment": ["ADT_TEST_TRIGGERS=%s" % triggers]}
                json.dump(d, testinfo, indent=True)
            files.add("testinfo.json")

    d = {}
    # we have to first check this file exists - when a package is marked with
    # dont_run for whatever reason, the file doesn't exist
    if os.path.isfile(os.path.join(dir, "testinfo.json")):
        with open(os.path.join(dir, "testinfo.json"), "r") as testinfo:
            try:
                d = json.load(testinfo)
            except json.decoder.JSONDecodeError as json_err:
                logging.warning(
                    "Loading testinfo failed with: %s\nCreating empty testinfo",
                    json_err,
                )
                d = {}
    d = inject_info_into_testinfo(d, additional_params, test_uuid)
    with open(os.path.join(dir, "testinfo.json"), "w") as testinfo:
        json.dump(d, testinfo, indent=True)

    with open(os.path.join(dir, "testpkg-version"), "r") as tpv:
        testpkg_version = tpv.read().split()[1]

    try:
        with open(os.path.join(dir, "duration"), "r") as dur:
            duration = dur.read()
    except FileNotFoundError:
        duration = None

    try:
        with open(os.path.join(dir, "requester"), "r") as req:
            requester = req.read()
    except FileNotFoundError:
        requester = None

    # these are small and we need only these for gating and indexing
    resultfiles = ["exitcode"]
    # these might not be present in infrastructure failure cases
    for f in [
        "testbed-packages",
        "testpkg-version",
        "duration",
        "testinfo.json",
        "requester",
        "summary",
    ]:
        if f in files:
            resultfiles.append(f)
    subprocess.check_call(["tar", "cf", "result.tar"] + resultfiles, cwd=dir)

    # compress main log file, for direct access
    subprocess.check_call(["gzip", "-9", os.path.join(dir, "log")])
    files.discard("log")

    # the readable-by file, if present, needs to stay intact and be uploaded
    # to the container as is, as it's used for ACL
    files.discard("readable-by")

    if files:
        # tar up all other artifacts
        subprocess.check_call(
            ["tar", "-czf", "artifacts.tar.gz"] + list(files), cwd=dir
        )
        for f in files:
            path = os.path.join(dir, f)
            if os.path.isdir(path):
                shutil.rmtree(path, ignore_errors=True)
            else:
                os.unlink(path)

    return (testpkg_version, duration, requester)


def series_to_version(series):
    versions = [x.version for x in ALL_RELEASES if x.series == series]
    if len(versions) < 1:
        return None
    return versions[0].strip(" LTS")


def i386_cross_series(series):
    # the first version where i386 is a partiel architecture and only cross
    # testing is done is 20.04
    return series_to_version(series) > "19.10"


def host_arch(release, architecture):
    if architecture != "i386":
        return architecture

    if not i386_cross_series(release):
        return architecture

    return "amd64"


def subst(s, big_package, release, architecture, hostarch, pkgname, test_uuid):
    subst = {
        "RELEASE": release,
        "ARCHITECTURE": architecture,
        "HOSTARCH": hostarch,
        "PACKAGENAME": pkgname,
        "PACKAGESIZE": cfg.get(
            "virt",
            big_package and "package_size_big" or "package_size_default",
        ),
        "TIMESTAMP": time.strftime("%Y%m%d-%H%M%S"),
        "HOSTNAME": hostname,
        "UUID": test_uuid,
    }
    for i in args.variable:
        k, v = i.split("=", 1)
        subst[k] = v

    for k, v in subst.items():
        s = s.replace("$" + k, v)
    return s


def send_status_info(
    queue,
    release,
    architecture,
    pkgname,
    params,
    out_dir,
    running,
    duration,
    test_uuid,
    private=False,
):
    """Send status and logtail to status queue"""

    if not queue:
        return

    if private:
        pkgname = "private-test"
        params = {}
        logtail = "Running private test"
    else:
        logtail = ""
        # print('status_info:', release, architecture, pkgname, out_dir, running)
        try:
            with open(os.path.join(out_dir, "log"), "rb") as f:
                # Always get the first 5 lines, as they are very valuable when
                # debugging problematic jobs
                logtail += f.readline().decode("UTF-8", errors="replace")
                logtail += f.readline().decode("UTF-8", errors="replace")
                logtail += f.readline().decode("UTF-8", errors="replace")
                logtail += f.readline().decode("UTF-8", errors="replace")
                logtail += f.readline().decode("UTF-8", errors="replace")
                logtail += "[... 🠉 HEAD 🠉 ... 🠋 TAIL 🠋 ...]\n"

                # Now get the tail of the log
                try:
                    f.seek(-2000, os.SEEK_END)
                    # throw away the first line as we almost surely cut that out in
                    # the middle
                    f.readline()
                except IOError:
                    # file is smaller than 2000 bytes? okay
                    pass
                logtail += f.read().decode("UTF-8", errors="replace")
        except (IOError, OSError) as e:
            logtail += "\nError reading log file: %s" % e

    msg = json.dumps(
        {
            "release": release,
            "architecture": architecture,
            "package": pkgname,
            "running": running,
            "params": params,
            "duration": duration,
            "logtail": logtail,
            "uuid": test_uuid,
        }
    )
    queue.basic_publish(amqp.Message(msg, delivery_mode=2), status_exchange_name, "")


def call_autopkgtest(
    argv,
    release,
    architecture,
    pkgname,
    params,
    out_dir,
    start_time,
    test_uuid,
    private=False,
):
    """Call autopkgtest and regularly send status/logtail to status_exchange_name

    Return exit code.
    """
    # set up status AMQP exchange
    global amqp_con
    status_amqp = amqp_con.channel()
    status_amqp.exchange_declare(
        status_exchange_name, "fanout", durable=False, auto_delete=True
    )

    null_fd = open("/dev/null", "w")
    autopkgtest = subprocess.Popen(argv, stdout=null_fd, stderr=subprocess.STDOUT)
    # FIXME: Use autopkgtest.wait(timeout=10) once moving to Python 3
    # only send status update every 30s, but check if program has finished every 1s
    status_update_counter = 0
    while autopkgtest.poll() is None:
        time.sleep(1)
        status_update_counter = (status_update_counter + 1) % 30
        if status_update_counter == 0:
            send_status_info(
                status_amqp,
                release,
                architecture,
                pkgname,
                params,
                out_dir,
                True,
                int(time.time() - start_time),
                test_uuid,
                private,
            )

    ret = autopkgtest.wait()
    send_status_info(
        status_amqp,
        release,
        architecture,
        pkgname,
        params,
        out_dir,
        False,
        int(time.time() - start_time),
        test_uuid,
        private,
    )

    status_amqp.close()

    return ret


def log_contents(out_dir):
    try:
        with open(
            os.path.join(out_dir, "log"),
            encoding="utf-8",
            errors="surrogateescape",
        ) as f:
            return f.read()
    except IOError as e:
        logging.error("Could not read log file: %s" % str(e))
        return ""


def cleanup_and_sleep(out_dir):
    """Empty the output dir for the next run, otherwise autopkgtest complains"""
    shutil.rmtree(out_dir, ignore_errors=True)
    os.mkdir(out_dir)
    retry_delay = int(cfg.get("autopkgtest", "retry_delay", fallback=30))
    time.sleep(retry_delay)


def request(msg):
    """Callback for AMQP queue request"""

    # Cleanup extras
    for extra in list(systemd_logging_handler._extra.keys()):
        if extra.startswith("ADT_"):
            del systemd_logging_handler._extra[extra]

    # Re-read in case the big/long/no run lists changed, would be better to
    # this only when needed via inotify.
    read_per_package_configs(cfg)

    dont_run = False
    private = False

    # FIXME: make this more elegant
    fields = msg.delivery_info["routing_key"].split("-")
    if len(fields) == 4:
        release, architecture = fields[2:4]
    elif len(fields) == 3:
        release, architecture = fields[1:3]
    else:
        raise NotImplementedError(
            "cannot parse queue name %s" % msg.delivery_info["routing_key"]
        )

    systemd_logging_handler._extra["ADT_RELEASE"] = release
    systemd_logging_handler._extra["ADT_ARCH"] = architecture

    try:
        worker_upstream_percentage = int(
            cfg["autopkgtest"]["worker_upstream_percentage"]
        )
    except Exception as _:
        worker_upstream_percentage = 33

    try:
        stable_release_percentage = int(cfg["autopkgtest"]["stable_release_percentage"])
    except Exception as _:
        stable_release_percentage = 100

    try:
        devel = distro_info.UbuntuDistroInfo().devel()
    except distro_info.DistroDataOutdated as _:
        logging.warning(
            (
                "distro_info detected as outdated, "
                "ignoring stable vs devel die roll mechanism"
            )
        )
        devel = None

    if devel and release != devel:
        if random.randint(1, 100) > stable_release_percentage:
            logging.info(
                "Stable release test request and 1d100 rolled above %i, skipping for now",
                stable_release_percentage,
            )
            msg.channel.basic_reject(msg.delivery_tag, requeue=True)
            return
        else:
            logging.info(
                "Stable release test request and 1d100 rolled below %i, running it now",
                stable_release_percentage,
            )

    if msg.delivery_info["routing_key"].startswith("debci-upstream-"):
        # crude way to not allow upstream tests to monopolise resources - only X%
        # of chances to really run them
        # This percentage is a juju config option.
        if random.randint(1, 100) > worker_upstream_percentage:
            logging.info(
                "Upstream job detected and 1d100 rolled above %i, skipping for now",
                worker_upstream_percentage,
            )
            msg.channel.basic_reject(msg.delivery_tag, requeue=True)
            return
        else:
            logging.info(
                "Upstream job detected and 1d100 rolled below %i, running it now",
                worker_upstream_percentage,
            )

    body = msg.body
    if isinstance(body, bytes):
        try:
            body = msg.body.decode("UTF-8")
        except UnicodeDecodeError as e:
            logging.error('Bad encoding in request "%s": %s', msg.body, e)
            msg.channel.basic_reject(msg.delivery_tag, requeue=False)
            return

    # request is either a single string pkgname or "pkg_name json_params"
    try:
        req = body.split("\n", 1)
        pkgname = req[0]
        if len(req) > 1:
            params = json.loads(req[1])
        else:
            params = {}
    except (ValueError, IndexError) as e:
        logging.error('Received invalid request format "%s" (%s)', body, repr(e))
        msg.channel.basic_reject(msg.delivery_tag, requeue=False)
        return
    test_uuid = params.get("uuid", str(uuid.uuid4()))
    if not re.match("[a-zA-Z0-9.+-]+$", pkgname):
        logging.error('Request contains invalid package name, dropping: "%s"', body)
        msg.channel.basic_reject(msg.delivery_tag, requeue=False)
        return

    systemd_logging_handler._extra["ADT_PACKAGE"] = pkgname
    systemd_logging_handler._extra["ADT_PARAMS"] = str(params)

    logging.info(
        "Received request for package %s on %s/%s; params: %s",
        pkgname,
        release,
        architecture,
        params,
    )

    current_region = os.environ.get("REGION")
    systemd_logging_handler._extra["ADT_REGION"] = current_region

    # build autopkgtest command line
    work_dir = tempfile.mkdtemp(prefix="autopkgtest-work.")

    try:
        out_dir = os.path.join(work_dir, "out")
        if (
            release.lower() in ARCH_RELEASE_ALLOW_MAPPING
            and architecture not in ARCH_RELEASE_ALLOW_MAPPING[release.lower()]
            and not request_matches_per_package(
                pkgname, architecture, release, esm_specials
            )
        ):
            os.makedirs(out_dir)
            # these will be written later on
            code = 99
            duration = 0
            logging.info(
                f"Only running {','.join(ARCH_RELEASE_ALLOW_MAPPING[release.lower()])} tests for release: {release.lower()}, test requests {architecture}"
            )
            # fake a log file
            with open(os.path.join(out_dir, "log"), "w") as log:
                log.write(
                    f"Only running {','.join(ARCH_RELEASE_ALLOW_MAPPING[release.lower()])} tests for release: {release.lower()}, you have requested {architecture}"
                )
            with open(os.path.join(out_dir, "testpkg-version"), "w") as testpkg_version:
                testpkg_version.write(
                    f"Package blacklisted we only run {','.join(ARCH_RELEASE_ALLOW_MAPPING[release.lower()])} tests for {release.lower()}"
                )
            dont_run = True
        elif request_matches_per_package(pkgname, architecture, release, never_run):
            logging.warning("Marked to never run, ignoring")
            dont_run = True

            # these will be written later on
            code = 99
            duration = 0

            os.makedirs(out_dir)

            # now let's fake up a log file
            with open(os.path.join(out_dir, "log"), "w") as log:
                log.write(
                    "This package is marked to never run. To get the entry removed, contact a member of the Ubuntu Release or Canonical Ubuntu QA team."
                )

            triggers = None
            # a json file containing the env
            if "triggers" in params:
                triggers = " ".join(params["triggers"])
                with open(os.path.join(out_dir, "testinfo.json"), "w") as testinfo:
                    d = {"custom_environment": ["ADT_TEST_TRIGGERS=%s" % triggers]}
                    json.dump(d, testinfo, indent=True)

            # and the testpackage version (pkgname blacklisted)
            # XXX: replace "blacklisted" here, but needs changes in
            # proposed-migration and hints
            with open(os.path.join(out_dir, "testpkg-version"), "w") as testpkg_version:
                testpkg_version.write("%s blacklisted" % pkgname)

        container = "autopkgtest-" + release
        big_pkg = request_matches_per_package(
            pkgname, architecture, release, big_packages
        )

        autopkgtest_checkout = cfg.get("autopkgtest", "checkout_dir").strip()
        if autopkgtest_checkout:
            argv = [os.path.join(autopkgtest_checkout, "runner", "autopkgtest")]
        else:
            argv = ["autopkgtest"]
        argv += ["--output-dir", out_dir, "--timeout-copy=6000"]

        if i386_cross_series(release) and architecture == "i386":
            argv += ["-a", "i386"]

        c = cfg.get("autopkgtest", "extra_args")
        if c:
            argv += c.strip().split()

        c = cfg.get("autopkgtest", "setup_command").strip()
        if c:
            c = subst(
                c,
                big_pkg,
                release,
                architecture,
                host_arch(release, architecture),
                pkgname,
                test_uuid,
            )
            argv += ["--setup-commands", c]
        c = cfg.get("autopkgtest", "setup_command2").strip()
        if c:
            c = subst(
                c,
                big_pkg,
                release,
                architecture,
                host_arch(release, architecture),
                pkgname,
                test_uuid,
            )
            argv += ["--setup-commands", c]

        if "triggers" in params and "qemu-efi-noacpi/0" in params["triggers"]:
            if architecture == "arm64":
                argv += [
                    "--setup-commands",
                    "/home/ubuntu/autopkgtest-cloud/worker-config-production/qemu-efi-noacpi.sh",
                ]
            else:
                # these will be written later on
                code = 99
                duration = 0

                os.makedirs(out_dir)
                # fake a log file
                with open(os.path.join(out_dir, "log"), "w") as log:
                    log.write(
                        "Not running due to invalid trigger: qemu-efi-noacpi/0 is arm64 only"
                    )
                dont_run = True

                # and the testpackage version (invalid trigger with a reason)
                with open(
                    os.path.join(out_dir, "testpkg-version"), "w"
                ) as testpkg_version:
                    testpkg_version.write(
                        "invalid trigger: qemu-efi-noacpi/0 is arm64 only"
                    )

        if "ppas" in params and params["ppas"]:
            for ppa in params["ppas"]:
                try:
                    (ppacreds, _, ppaurl) = ppa.rpartition("@")
                    (ppaurl, _, fingerprint) = ppaurl.partition(":")
                    (ppacreds_user, ppacreds_pass) = (
                        ppacreds.split(":") if ppacreds else (None, None)
                    )
                    (ppauser, ppaname) = ppaurl.split("/")
                except ValueError:
                    logging.error(
                        "Invalid PPA specification, must be [user:token@]lpuser/ppa_name[:fingerprint]"
                    )
                    msg.channel.basic_reject(msg.delivery_tag, requeue=False)
                    return
                logging.debug(
                    "Request states that PPA user '%s', name '%s' has GPG fingerprint '%s'"
                    % (ppauser, ppaname, fingerprint)
                )
                if ppacreds_user:
                    # Any run with at least one private PPA needs to be private.
                    private = True
                    ppaprefix = "%s:%s@" % (
                        ppacreds_user,
                        ppacreds_pass,
                    )
                else:
                    ppaprefix = ""
                if fingerprint:
                    fingerprint = f":{fingerprint}"
                else:  # Make sure fingerprint is an empty string, and not some other False-ish value
                    fingerprint = ""
                argv += [
                    f"--add-apt-source=ppa:{ppaprefix}{ppauser}/{ppaname}{fingerprint}"
                ]

            # put results into separate container, named by the last PPA
            container += "-%s-%s" % (ppauser, ppaname)

        # only install the triggering package from -proposed, rest from -release
        # this provides better isolation between -proposed packages; but only do
        # that for Ubuntu itself, not for things from git, PPAs, etc.
        # also skip that for the kernel as the linux vs. linux-meta split always
        # screws up the apt pinning
        if cfg.get("virt", "args") != "null":
            if (
                "test-git" not in params
                and "test-bzr" not in params
                and ("ppas" not in params or "all-proposed" in params)
            ):
                pocket_arg = "--apt-pocket=proposed"
                if "all-proposed" not in params and not pkgname.startswith("linux"):
                    trigs = [
                        "src:" + t.split("/", 1)[0]
                        for t in params.get("triggers", [])
                        if t not in ("migration-reference/0", "qemu-efi-noacpi/0")
                    ]
                    if trigs:
                        pocket_arg += "=" + ",".join(trigs)
                    else:
                        pocket_arg = ""
                if pocket_arg:
                    argv.append(pocket_arg)
            argv.append("--apt-upgrade")

        # determine which test to run
        if "test-git" in params:
            testargs = ["--no-built-binaries", params["test-git"]]
        elif "build-git" in params:
            testargs = [params["build-git"]]
        elif "test-bzr" in params:
            checkout_dir = os.path.join(work_dir, "checkout")
            subprocess.check_call(
                [
                    "bzr",
                    "checkout",
                    "--lightweight",
                    params["test-bzr"],
                    checkout_dir,
                ]
            )
            testargs = ["--no-built-binaries", checkout_dir]
        else:
            testargs = [pkgname]

        argv += testargs
        global debug
        if debug:
            argv.append("--debug")

        timeout_short = 300
        timeout_long = 20000

        if architecture == "riscv64":
            # xypron suggested a factor 4 for riscv64 when emulated
            timeout_short = timeout_short * 4
            timeout_long = timeout_long * 4

        argv.append(f"--timeout-short={timeout_short}")
        if request_matches_per_package(pkgname, architecture, release, long_tests):
            argv.append(f"--timeout-copy={timeout_long * 2}")
            argv.append(f"--timeout-test={timeout_long * 2}")
            argv.append(f"--timeout-build={timeout_long * 2}")
        elif big_pkg:
            argv.append(f"--timeout-copy={timeout_long}")
            argv.append(f"--timeout-test={timeout_long}")
            argv.append(f"--timeout-build={timeout_long}")
        else:
            argv.append(f"--timeout-copy={timeout_long}")
            argv.append(f"--timeout-build={timeout_long}")

        for e in params.get("env", []):
            argv.append("--env=%s" % e)

        triggers = None
        if "triggers" in params:
            triggers = " ".join(params["triggers"])
            argv.append("--env=ADT_TEST_TRIGGERS=%s" % triggers)

            # want to run against a non-default kernel?
            for t in params["triggers"]:
                if t.startswith("linux-meta"):
                    totest = t.split("/")[0].replace("linux-meta", "linux")

                    # XXX: this is all legacy code guessing the package name to
                    # install from the series and source.  We are moving to a
                    # consistent Provides: on the first flavour meta package.
                    # Generated by replacing -meta with -image and -headers.
                    flavor = t.split("/")[0].replace("linux-meta", "")

                    # HWE kernels have their official release name in the binary package names.
                    if flavor.startswith("-hwe"):
                        ubuntu_version = series_to_version(release)
                        if ubuntu_version:
                            flavor = flavor.replace("-hwe", "-hwe-" + ubuntu_version, 1)
                    # OEM kernels have their official release name in the binary
                    # package names.
                    # The source package names are of the form linux-meta-oem-XX.YY
                    # where XX and YY are kernel version numbers. The binary
                    # package names are linux-image-oem-MM.NN where MM and NN are
                    # Ubuntu release numbers (i.e. year and month).
                    elif any(
                        flavor.startswith(x)
                        for x in ("-oem-{}".format(n) for n in range(5, 10))
                    ):
                        ubuntu_version = series_to_version(release)
                        if ubuntu_version:
                            flavor = "-oem-{}".format(ubuntu_version)
                    elif flavor == "-ti-omap4":
                        # yay consistency
                        argv += [
                            "--setup-commands",
                            "apt-get install -y linux-omap4",
                        ]

                    # escape dots in flavor
                    totest = re.escape(totest)
                    flavor = re.escape(flavor)

                    argv += [
                        "--setup-commands",
                        (
                            "apt-get install -y ^kernel-testing--%(t)s--full--preferred$ || "
                            + "apt-get install -y ^linux-image%(f)s$ ^linux-headers%(f)s$ || "
                            + "apt-get install -y ^linux-image-generic%(f)s$ ^linux-headers-generic%(f)s$"
                        )
                        % {"f": flavor, "t": totest},
                    ]
                    argv += [
                        "--setup-commands",
                        (
                            "apt-get install -y ^kernel-testing--%(t)s--modules-extra--preferred$ || "
                            + "apt-get install -y ^linux-modules-extra%(f)s$ || :"
                        )
                        % {"f": flavor, "t": totest},
                    ]
                    break

        if "testname" in params:
            argv.append("--testname=%s" % params["testname"])

        argv.append("--")
        argv += subst(
            cfg.get("virt", "args"),
            big_pkg,
            release,
            architecture,
            host_arch(release, architecture),
            pkgname,
            test_uuid,
        ).split()

        if "swiftuser" in params:
            private = True
        elif private:
            # Some combination already marked the run as private, but no
            # swiftuser user has been specified. This is not valid, as otherwise
            # no one would be realistically able to read back the results.
            logging.error(
                "Private autopkgtest run detected but no swiftuser identity provided."
            )
            msg.channel.basic_reject(msg.delivery_tag, requeue=False)
            return

        if private:
            container = "private-{}".format(container)

        # run autopkgtest; retry up to three times on tmpfail issues
        if not dont_run:
            global running_test
            running_test = True
            start_time = time.time()
            num_failures = 0
            for retry in range(3):
                retry_start_time = time.time()
                logging.info("Running %s", " ".join(argv))
                code = call_autopkgtest(
                    argv,
                    release,
                    architecture,
                    pkgname,
                    params,
                    out_dir,
                    start_time,
                    test_uuid,
                    private,
                )
                is_failure = code in FAIL_CODES
                is_success = code in SUCCESS_CODES
                files = set(os.listdir(out_dir))
                is_unknown_version = "testpkg-version" not in files

                retrying = "Retrying in 5 minutes... " if retry < 2 else ""

                if is_success:
                    break
                elif is_failure and is_unknown_version and retry < 2:
                    # this is an 'unknown' result; try three times but fail
                    # properly after that (do not tmpfail)
                    contents = log_contents(out_dir)
                    logging.warning(
                        "Test run failed with no version. %sLog follows:",
                        retrying,
                    )
                    logging.error(contents)
                    submit_metric(
                        architecture,
                        code,
                        pkgname,
                        current_region,
                        True,
                        release,
                    )
                    cleanup_and_sleep(out_dir)
                elif is_failure:
                    contents = log_contents(out_dir)
                    temp_fails = [
                        s
                        for s in (
                            set(TEMPORARY_TEST_FAIL_STRINGS)
                            - set(getglob(OK_PKG_STRINGS, pkgname, []))
                        )
                        if s in contents
                    ]
                    if temp_fails:
                        logging.warning(
                            "Saw %s in log, which is a sign of a temporary failure.",
                            " and ".join(temp_fails),
                        )
                        logging.warning("%sLog follows:", retrying)
                        logging.error(contents)
                        if retry < 2:
                            submit_metric(
                                architecture,
                                code,
                                pkgname,
                                current_region,
                                True,
                                release,
                            )
                            cleanup_and_sleep(out_dir)
                    else:
                        break
                elif code == 16:
                    contents = log_contents(out_dir)
                    if exit_requested is not None:
                        logging.warning(
                            "Testbed failure and exit %i requested. Log follows:",
                            exit_requested,
                        )
                        logging.error(contents)
                        sys.exit(exit_requested)
                    # Get the package-specific string for triggers too, since they might have broken the run
                    trigs = [t.split("/", 1)[0] for t in params.get("triggers", [])]
                    fail_trigs = [
                        j
                        for i in [getglob(FAIL_PKG_STRINGS, trig, []) for trig in trigs]
                        for j in i
                    ]

                    # Or if all-proposed, just give up and accept everything
                    fail_all_proposed = [
                        j for i in FAIL_PKG_STRINGS.values() for j in i
                    ]

                    allowed_fail_strings = set(
                        FAIL_STRINGS
                        + getglob(FAIL_PKG_STRINGS, pkgname, [])
                        + fail_trigs
                        + (fail_all_proposed if "all-proposed" in params else [])
                    ) - set(getglob(OK_PKG_STRINGS, pkgname, []))

                    fails = [s for s in allowed_fail_strings if s in contents] + [
                        s for s in FAIL_STRINGS_REGEX if re.search(s, contents)
                    ]

                    if fails:
                        num_failures += 1
                        logging.warning(
                            "Saw %s in log, which is a sign of a real (not tmp) failure - seen %d so far",
                            " and ".join(fails),
                            num_failures,
                        )
                    logging.warning("Testbed failure. %sLog follows:", retrying)
                    logging.error(contents)
                    if retry < 2:
                        submit_metric(
                            architecture,
                            code,
                            pkgname,
                            current_region,
                            True,
                            release,
                        )
                        cleanup_and_sleep(out_dir)
                else:
                    # This block is reached in edge cases with undefined failures,
                    # and also when a test is requested to be killed by an admin
                    # tests can be requested to be killed with:
                    # kill -15 $pid
                    logging.warning(
                        "autopkgtest exited with code: %i",
                        code,
                    )
                    running_test = False
                    # we ack the message so it doesn't go back in the queue
                    if exit_requested is not None:
                        logging.info(
                            "An exit has been requested via systemd, placing message %s back in queue",
                            body.encode(),
                        )
                        msg.channel.basic_reject(msg.delivery_tag, requeue=True)
                        return
                    else:
                        logging.warning(
                            "autopkgtest has failed with an unknown code (%i), trying test %s again...",
                            code,
                            body.encode(),
                        )
            else:
                if num_failures >= 3:
                    logging.warning(
                        "Three fails in a row - considering this a failure rather than tmpfail"
                    )
                    code = 4
                else:
                    logging.warning(
                        (
                            "Three testbed failures in a row - considering this a legitimate "
                            f"testbed failure rather than tmpfail. Not retrying the following message: {body}"
                        )
                    )
                    code = 16

            duration = int(time.time() - retry_start_time)

        logging.info("autopkgtest exited with code %i", code)
        submit_metric(architecture, code, pkgname, current_region, False, release)
        if code == 1:
            logging.error("autopkgtest exited with unexpected error code 1")
            sys.exit(1)
        with open(os.path.join(out_dir, "exitcode"), "w") as f:
            f.write("%i\n" % code)
        with open(os.path.join(out_dir, "duration"), "w") as f:
            f.write("%u\n" % duration)

        if "requester" in params:
            with open(os.path.join(out_dir, "requester"), "w") as f:
                f.write("%s\n" % params["requester"])

        if "readable-by" in params:
            with open(os.path.join(out_dir, "readable-by"), "w") as f:
                if isinstance(params["readable-by"], list):
                    f.write("\n".join(params["readable-by"]))
                else:
                    f.write("%s\n" % params["readable-by"])

        # List of key=value strings to be sent as a rabbitmq msg
        # These variables are optional additional parameters users
        # can employ when requesting a test which alters the behaviour
        additional_parameters = {}
        for key in KEYS_FOR_ADDITIONAL_PARAMS:
            if params.get(key, None) is not None:
                additional_parameters[key] = params[key]

        (testpkg_version, duration, requester) = process_output_dir(
            out_dir,
            pkgname,
            code,
            params.get("triggers", []),
            test_uuid,
            additional_parameters,  # embed additional parameters in testinfo.json
        )

        # If two tests for the same package with different triggers finish at the
        # same second, we get collisions with just the timestamp; disambiguate with
        # the hashed params. We append a '@' which is a nice delimiter for querying
        # runs in swift.
        run_id = "%s_%s@" % (
            time.strftime("%Y%m%d_%H%M%S", time.gmtime()),
            hashlib.sha1(body.encode("UTF-8")).hexdigest()[:5],
        )
        if pkgname.startswith("lib"):
            prefix = pkgname[:4]
        else:
            prefix = pkgname[0]
        swift_dir = os.path.join(release, architecture, prefix, pkgname, run_id)

        global swift_upload
        if swift_upload:
            # publish results into swift
            logging.info("Putting results into swift %s %s", container, swift_dir)

            # create it if it does not exist yet
            swift_con = swiftclient.Connection(**swift_creds)
            try:
                swift_con.get_container(container, limit=1)
            except swiftclient.exceptions.ClientException:
                logging.info("container %s does not exist, creating it", container)
                if private:
                    # private result, share only with swiftuser
                    swift_con.put_container(
                        container,
                        headers={"X-Container-Read": "*:%s" % params["swiftuser"]},
                    )
                else:
                    # make it publicly readable
                    swift_con.put_container(
                        container,
                        headers={"X-Container-Read": ".rlistings,.r:*"},
                    )
                # wait until it exists
                timeout = 50
                while timeout > 0:
                    try:
                        swift_con.get_container(container, limit=1)
                        logging.debug(
                            "newly created container %s exists now", container
                        )
                        break
                    except swiftclient.exceptions.ClientException:
                        logging.debug(
                            "newly created container %s does not exist yet, continuing poll",
                            container,
                        )
                        time.sleep(1)
                        timeout -= 1
                else:
                    logging.error(
                        "timed out waiting for newly created container %s",
                        container,
                    )
                    sys.exit(1)

            for f in os.listdir(out_dir):
                path = os.path.join(out_dir, f)
                with open(path, "rb") as fd:
                    if path.endswith("log.gz"):
                        content_type = "text/plain; charset=UTF-8"
                        headers = {"Content-Encoding": "gzip"}
                    else:
                        content_type = None
                        headers = None

                    sleep_time = 10
                    for retry in reversed(range(5)):
                        try:
                            # swift_con.put_object() is missing the name kwarg
                            swiftclient.put_object(
                                swift_con.url,
                                token=swift_con.token,
                                container=container,
                                name=os.path.join(swift_dir, f),
                                contents=fd,
                                content_type=content_type,
                                headers=headers,
                                content_length=os.path.getsize(path),
                            )
                            break
                        except Exception as e:
                            if retry > 0:
                                logging.info(
                                    "Failed to upload %s to swift (%s), retrying in %s seconds..."
                                    % (path, str(e), sleep_time)
                                )
                                time.sleep(sleep_time)
                                sleep_time *= 2
                                continue

                            raise

            swift_con.close()
    finally:
        if swift_upload:
            shutil.rmtree(work_dir, ignore_errors=True)
        else:
            logging.info("Keeping results in %s", work_dir)

    global amqp_con
    complete_amqp = amqp_con.channel()
    complete_amqp.exchange_declare(
        complete_exchange_name, "fanout", durable=True, auto_delete=False
    )
    complete_msg = json.dumps(
        {
            "architecture": architecture,
            "container": container,
            "duration": duration,
            "exitcode": code,
            "package": pkgname,
            "testpkg_version": testpkg_version,
            "release": release,
            "requester": requester,
            "swift_dir": swift_dir,
            "triggers": triggers,
            "env": ",".join(
                [f"{key}={value}" for key, value in additional_parameters.items()]
            ),
            "uuid": test_uuid,
        }
    )
    complete_amqp.basic_publish(
        amqp.Message(complete_msg, delivery_mode=2), complete_exchange_name, ""
    )
    complete_amqp.close()

    logging.info("Acknowledging request %s" % body)
    msg.channel.basic_ack(msg.delivery_tag)
    running_test = False


def amqp_connect(cfg):
    """Connect to AMQP host using given configuration

    Connect `request` to queues for all configured releases and
    architectures.

    Return queue object.
    """
    global amqp_con
    logging.info("Connecting to AMQP server %s", os.environ["RABBIT_HOST"])
    amqp_con = amqp.Connection(
        os.environ["RABBIT_HOST"],
        userid=os.environ["RABBIT_USER"],
        password=os.environ["RABBIT_PASSWORD"],
        confirm_publish=True,
    )
    amqp_con.connect()
    queue = amqp_con.channel()
    # avoids greedy grabbing of the entire queue while being too busy
    queue.basic_qos(0, 1, True)

    arch = args.architecture

    # avoid preferring the same architecture on all workers
    queues = []

    contexts = ["", "huge-", "ppa-", "upstream-"]

    for release in cfg.get("autopkgtest", "releases").split():
        for context in contexts:
            queue_name = "debci-%s%s-%s" % (context, release, arch)
            queues.append(queue_name)

    random.shuffle(queues)

    for queue_name in queues:
        logging.info("Setting up and listening to AMQP queue %s", queue_name)
        queue.queue_declare(queue_name, durable=True, auto_delete=False)
        queue.basic_consume(queue=queue_name, callback=request)

    return amqp_con


def main():
    """Main program"""

    global cfg, args, swift_creds, swift_upload, debug

    args = parse_args()

    signal.signal(signal.SIGTERM, term_handler)
    signal.signal(signal.SIGHUP, hup_handler)

    # load configuration
    cfg = configparser.ConfigParser(
        {
            "setup_command": "",
            "setup_command2": "",
            "checkout_dir": "",
            "package_size_default": "",
            "package_size_big": "",
            "extra_args": "",
            "debug": "",
        },
        allow_no_value=True,
    )
    with open(args.config, "r") as f:
        cfg.read_file(f)

    if args.debug or cfg.get("autopkgtest", "debug").lower() in [
        "1",
        "true",
        "yes",
    ]:
        debug = True

    handlers = None
    if "INVOCATION_ID" in os.environ:
        handlers = [systemd_logging_handler]
    logging.basicConfig(
        level=(debug and logging.DEBUG or logging.INFO),
        format="%(levelname)s: %(message)s",
        handlers=handlers,
    )
    if debug:
        logging.info("Debug enabled")
    else:
        logging.info("Debug disabled")

    try:
        os.environ["SWIFT_AUTH_URL"]
    except KeyError:
        logging.warning(
            "No SWIFT_AUTH_URL detected, disabling swift upload and keeping results locally instead"
        )
        swift_upload = False

    if swift_upload:
        swift_creds = {
            "authurl": os.environ["SWIFT_AUTH_URL"],
            "user": os.environ["SWIFT_USERNAME"],
            "key": os.environ["SWIFT_PASSWORD"],
            "os_options": {
                "project_domain_name": os.environ["SWIFT_PROJECT_DOMAIN_NAME"],
                "project_name": os.environ["SWIFT_PROJECT_NAME"],
                "user_domain_name": os.environ["SWIFT_USER_DOMAIN_NAME"],
            },
            "auth_version": "3",
        }

        # ensure that we can connect to swift
        swiftclient.Connection(**swift_creds).close()

    # connect to AMQP queues
    amqp_con = amqp_connect(cfg)

    # process queues forever
    try:
        while exit_requested is None:
            logging.info("Waiting for and processing AMQP requests")
            amqp_con.drain_events()
    except IOError:
        if exit_requested is None:
            raise


if __name__ == "__main__":
    main()
    if exit_requested:
        logging.info("Exiting with %i due to queued exit request" % exit_requested)
        sys.exit(exit_requested)
